{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serverless Transfer Learning with Cloud ML Engine and Keras\n",
    "\n",
    "The notebook is based on [article](https://medium.com/google-cloud/serverless-transfer-learning-with-cloud-ml-engine-and-keras-335435f31e15).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install required package.\n",
    "\n",
    "Install cloudmlmagic ahead of running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cloudmlmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load cloudmlmagic extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext cloudmlmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and setup ML Engine parameters.\n",
    "Following dict will be written in setup.py of your package,\n",
    "so list up neccesary packages of your code.\n",
    "\n",
    "** NOTE: Please replace with your own project id and bucket where to save trained model in following two cells **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%ml_init -projectId datalab-trial-186403 -bucket cloudml_models/transfer_learning -scaleTier BASIC -region us-central1 -runtimeVersion 1.2 \n",
    "{'install_requires': ['keras', 'h5py', 'Pillow']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PROJECTID=datalab-trial-186403\n",
    "%env BUCKET=cloudml_models/transfer_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception-v3 in Keras\n",
    "\n",
    "It is quite easy to use a pre-trained model in Keras, only two lines as follows.\n",
    "\n",
    "This model was pre-trained with ImageNet’s datasets, which has one million images and 1000 classes.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*ZCXqy5c-MwRzJlo7rYPyRQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ml_code\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "model = InceptionV3(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%ml_code\n",
    "\n",
    "# Imports Keras packages and model\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s classify following two images with this model. Since Inception-v3 model accepts RGB 299x299 image as input, you must convert your image before classify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inline display image\n",
    "from IPython.display import display\n",
    "\n",
    "def predict(img_path):\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    # Display image\n",
    "    display(img)\n",
    "    \n",
    "    # Classify image\n",
    "    preds = model.predict(x)\n",
    "    \n",
    "    # Print predicted classes\n",
    "    print('Predicted:')\n",
    "    for p in decode_predictions(preds, top=5)[0]:\n",
    "        print(\"Score {}, Label {}\".format(p[2], p[1]))    \n",
    "        \n",
    "predict('Indian_elephant.jpeg')\n",
    "predict('Gull.jpeg')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The model classified elephants correctly, but failed to classify a seagull. The reason is simply because datasets for training the model doesn’t include “gull”, so that it classified similar candidates instead. You never get results out of the list, and that’s why transfer learning is needed.\n",
    "\n",
    "## Visualize intermediate layer outputs\n",
    "\n",
    "Before going to transfer learning, let’s visualize intermediate layer outputs. To show list of layers, run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Will allow us to embed images in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(model.layers).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to visualize outputs of layer 311, `GlobalAveragePooling2D`, so let’s construct a model to output the intermediate layer outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%ml_code\n",
    "from keras.models import Model\n",
    "\n",
    "# The model which outputs intermediate layer features\n",
    "intermediate_layer_model = Model(inputs=model.input, \n",
    "                                 outputs=model.layers[311].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract features and visualize, run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img_path):\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    # Display image\n",
    "    display(img)\n",
    "    \n",
    "    # Extract features\n",
    "    features = intermediate_layer_model.predict(x)\n",
    "\n",
    "    # Visualize\n",
    "    pd.DataFrame(features.reshape(-1,1)).plot(figsize=(12, 3))\n",
    "    \n",
    "extract_features('Indian_elephant.jpeg')\n",
    "extract_features('Gull.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs of `GlobalAveragePooling2D` are 2048 dimensions features. Inception-v3 model classifies 1000 classes by using Dense layer at the end of the network, which uses these features as input. But now, we would like to classify “other” classes. So let’s remove this layer and put another one.\n",
    "\n",
    "## Add Dense layers for fine tuning\n",
    "\n",
    "Let’s add dense layers, if we want to classify **two-classes**, the code would be something like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%ml_code\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Connect Dense layers at the end\n",
    "x = intermediate_layer_model.output\n",
    "# Add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# Add a logistic layer -- let's say we have 2 classes\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# This is the model we will train which is Transfer Learning model\n",
    "transfer_model = Model(inputs=intermediate_layer_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize transfer layer outputs\n",
    "\n",
    "Let’s visualize transfer layer outputs. To show list of layers, run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transfer_model.layers).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this moment, the model trains all its variables. But we want to train only the dense layers we added, so let’s freeze untrained layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%ml_code\n",
    "\n",
    "# Freeze all layers\n",
    "for layer in transfer_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Unfreeze last dense layers\n",
    "transfer_model.layers[312].trainable = True\n",
    "transfer_model.layers[313].trainable = True\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "transfer_model.compile(loss='categorical_crossentropy',\n",
    "                       # Adam is an optimization algorithm that can used instead of \n",
    "                       # the classical stochastic gradient descent procedure to update network weights iterative \n",
    "                       # based in training data.\n",
    "                       optimizer='adam',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! Now we can fine-tune this model for dedicated two-classes classification.\n",
    "\n",
    "Fine tuning for two-classes classification\n",
    "Let’s classify the images below. the datasets is named Opera-Capitol datasets, which includes Opera house and Capitol 100 images for each. You can download the code to make this datasets.\n",
    "https://github.com/hayatoy/deep-learning-datasets\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*iHxe57geQ_CkXsdYnu-ZWw.png)\n",
    "\n",
    "## Load dataset\n",
    "\n",
    "The dataset is compressed as NumPy format and stored in GitHub, you can use it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%ml_code\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "url = 'https://github.com/hayatoy/deep-learning-datasets/releases/download/v0.1/tl_opera_capitol.npz'\n",
    "response = requests.get(url)\n",
    "dataset = np.load(BytesIO(response.content))\n",
    "\n",
    "X_dataset = dataset['features']\n",
    "y_dataset = dataset['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s split the dataset into for train and for test, here I split it 80% for train and 20% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%ml_code\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_dataset = preprocess_input(X_dataset)\n",
    "y_dataset = np_utils.to_categorical(y_dataset)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_dataset, y_dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning the model for Opera-Capitol\n",
    "\n",
    "To train the transfer learning model, just call `fit` function. After that, let’s evaluate the model how it predict correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%ml_code\n",
    "\n",
    "def fine_tuning(epochs=5):\n",
    "    transfer_model.fit(X_train, y_train, epochs,\n",
    "                       validation_data=(X_test, y_test))\n",
    "    loss, acc = transfer_model.evaluate(X_test, y_test)\n",
    "    print('Loss {}, Accuracy {}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoking the function fine_tuning() below to train the model locally, and this might take you couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict2(img_path):\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    # Display image\n",
    "    display(img)\n",
    "    \n",
    "    # Classify image\n",
    "    preds = transfer_model.predict(x)\n",
    "    \n",
    "    # Print predicted classes\n",
    "    print('Predicted:')\n",
    "    print(\"Score {}, Label {}\".format(preds[0][0], 'Opera'))\n",
    "    print(\"Score {}, Label {}\".format(preds[0][1], 'Capitol'))\n",
    "        \n",
    "predict2('Opera_house.jpeg')\n",
    "predict2('United_states_capitol.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cloud ML Engine from Jupyter Notebook\n",
    "\n",
    "Before you begin, prepare [Google Cloud Platform](https://cloud.google.com/) project, enable billing and install [Google Cloud SDK](https://cloud.google.com/sdk/downloads).\n",
    "\n",
    "To activate the credentials, enter:\n",
    "\n",
    "```\n",
    "% gcloud auth application-default login\n",
    "```\n",
    "\n",
    "To list credential account, enter:\n",
    "\n",
    "```\n",
    "%gcloud auth list\n",
    "\n",
    "Credentialed Accounts\n",
    "ACTIVE  ACCOUNT\n",
    "*       <myaccount>@<mydomain>\n",
    "```\n",
    "\n",
    "To list project, enter:\n",
    "\n",
    "```\n",
    "% gcloud config list project\n",
    "\n",
    "[core]\n",
    "project = <PROJECT_ID>\n",
    "```\n",
    "\n",
    "If it is not, you can set it with this command:\n",
    "\n",
    "```\n",
    "% gcloud config set project <PROJECT_ID>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%ml_code\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "def save_model(export_dir):\n",
    "    # The learning phase flag is a bool tensor (0 = test, 1 = train) to be passed as input to any Keras function \n",
    "    # that uses a different behavior at train time and test time.\n",
    "    K.set_learning_phase(0)\n",
    "    sess = K.get_session()\n",
    "\n",
    "    from tensorflow.python.framework import graph_util\n",
    "\n",
    "    # Make GraphDef of Transfer Model\n",
    "    g_trans = sess.graph\n",
    "    # Replaces all the variables in a graph with constants of the same values.\n",
    "    # If you have a trained graph containing Variable ops, it can be convenient to convert them all to Const ops \n",
    "    # holding the same values. This makes it possible to describe the network fully with a single GraphDef file, \n",
    "    # and allows the removal of a lot of ops related to loading and saving the variables.\n",
    "    g_trans_def = graph_util.convert_variables_to_constants(\n",
    "                    sess,\n",
    "                    g_trans.as_graph_def(),\n",
    "                    [transfer_model.output.name.replace(':0','')])\n",
    "\n",
    "    # Image Converter Model\n",
    "    with tf.Graph().as_default() as g_input:\n",
    "        input_b64 = tf.placeholder(shape=(1,), dtype=tf.string, name='input')\n",
    "        input_bytes = tf.decode_base64(input_b64[0])\n",
    "        # Detects whether an image is a BMP, GIF, JPEG, or PNG, and performs the appropriate operation to convert \n",
    "        # the input bytes string into a Tensor of type uint8.\n",
    "        image = tf.image.decode_image(input_bytes)\n",
    "        # Convert image to dtype, scaling its values if needed.\n",
    "        # Images that are represented using floating point values are expected to have values in the range [0,1). \n",
    "        # Image data stored in integer data types are expected to have values in the range [0,MAX], \n",
    "        # where MAX is the largest positive representable number for the data type.\n",
    "        # This op converts between data types, scaling the values appropriately before casting.\n",
    "        image_f = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "        # Inserts a dimension of 1 into a tensor's shape.\n",
    "        input_image = tf.expand_dims(image_f, 0)\n",
    "        # Return a tensor with the same shape and contents as input.\n",
    "        output = tf.identity(input_image, name='input_image')\n",
    "\n",
    "    g_input_def = g_input.as_graph_def()\n",
    "\n",
    "    with tf.Graph().as_default() as g_combined:\n",
    "        x = tf.placeholder(tf.string, name=\"input_b64\")\n",
    "\n",
    "        im, = tf.import_graph_def(g_input_def,\n",
    "                                  # A dictionary mapping input names (as strings) in graph_def to Tensor objects. \n",
    "                                  # The values of the named input tensors in the imported graph will be re-mapped \n",
    "                                  # to the respective Tensor values.\n",
    "                                  input_map={'input:0': x},\n",
    "                                  return_elements=[\"input_image:0\"])\n",
    "\n",
    "        pred, = tf.import_graph_def(g_trans_def,\n",
    "                                     input_map={transfer_model.input.name: im,\n",
    "                                                 'batch_normalization_1/keras_learning_phase:0': False},\n",
    "                                     return_elements=[transfer_model.output.name])\n",
    "\n",
    "        with tf.Session() as sess2:\n",
    "            inputs = {\"inputs\": tf.saved_model.utils.build_tensor_info(x)}\n",
    "            outputs = {\"outputs\": tf.saved_model.utils.build_tensor_info(pred)}\n",
    "            signature = tf.saved_model.signature_def_utils.build_signature_def(\n",
    "                inputs=inputs,\n",
    "                outputs=outputs,\n",
    "                method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n",
    "            )\n",
    "\n",
    "            # save as SavedModel\n",
    "            #export_dir = './savedmodel'\n",
    "            b = tf.saved_model.builder.SavedModelBuilder(export_dir)\n",
    "            b.add_meta_graph_and_variables(sess2,\n",
    "                                           [tf.saved_model.tag_constants.SERVING],\n",
    "                                           signature_def_map={'serving_default': signature})\n",
    "            b.save()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ml_run cloud\n",
    "\n",
    "# Invoking the function fine_tuning() to train the model.\n",
    "fine_tuning(epochs=20)\n",
    "\n",
    "# Remove previous saved model from GS\n",
    "\n",
    "# Invoking the function save_model() to save the model.\n",
    "save_model('gs://cloudml_models/transfer_learning/savedmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is to prevent \"runAll\".\n",
    "# you must wait until ML Engine job finishes\n",
    "raise Exception('wait until ml engine job finishes..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Create Model and Version for Online Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options are [europe-west1, us-central1]\n",
    "# Only need to create models first time.\n",
    "#!gcloud ml-engine models create OperaCapitol --regions us-central1\n",
    "!gcloud ml-engine versions create v1 --model OperaCapitol --runtime-version 1.2 --origin gs://$BUCKET/savedmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "\n",
    "PROJECTID = os.getenv('PROJECTID')\n",
    "projectID = 'projects/{}'.format(PROJECTID)\n",
    "modelName = 'OperaCapitol'\n",
    "modelID = '{}/models/{}'.format(projectID, modelName)\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "ml = discovery.build('ml', 'v1', credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "\n",
    "def predict3(img_path):\n",
    "    # Display image\n",
    "    img = image.load_img(img_path, target_size=(299, 299))    \n",
    "    display(img)\n",
    "\n",
    "    with open(img_path, 'rb') as f:\n",
    "        b64_x = f.read()\n",
    "\n",
    "    b64_x = base64.urlsafe_b64encode(b64_x)\n",
    "    # Keys should be the names of Tensors your deployed model expects as inputs.\n",
    "    input_instance = dict(inputs=b64_x)\n",
    "    input_instance = json.loads(json.dumps(input_instance))\n",
    "    request_body = {\"instances\": [input_instance]}\n",
    "\n",
    "    request = ml.projects().predict(name=modelID, body=request_body)\n",
    "    try:\n",
    "        response = request.execute()\n",
    "    except errors.HttpError as err:\n",
    "        # Something went wrong with the HTTP transaction.\n",
    "        # To use logging, you need to 'import logging'.\n",
    "        print('There was an HTTP error during the request:')\n",
    "        print(err._get_reason())\n",
    "    print(response)\n",
    "        \n",
    "predict3('Opera_house.jpeg')\n",
    "predict3('United_states_capitol.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
