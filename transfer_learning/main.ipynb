{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception-v3 in Keras\n",
    "\n",
    "It is quite easy to use a pre-trained model in Keras, only two lines as follows.\n",
    "\n",
    "This model was pre-trained with ImageNet’s datasets, which has one million images and 1000 classes.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*ZCXqy5c-MwRzJlo7rYPyRQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "model = InceptionV3(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inline display image\n",
    "from IPython.display import display\n",
    "\n",
    "# Imports Keras packages and model\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s classify following two images with this model. Since Inception-v3 model accepts RGB 299x299 image as input, you must convert your image before classify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img_path):\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    # Display image\n",
    "    display(img)\n",
    "    \n",
    "    # Classify image\n",
    "    preds = model.predict(x)\n",
    "    \n",
    "    # Print predicted classes\n",
    "    print('Predicted:')\n",
    "    for p in decode_predictions(preds, top=5)[0]:\n",
    "        print(\"Score {}, Label {}\".format(p[2], p[1]))    \n",
    "\n",
    "        \n",
    "predict(model, 'Indian_elephant.jpeg')\n",
    "predict(model, 'Gull.jpeg')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The model classified elephants correctly, but failed to classify a seagull. The reason is simply because datasets for training the model doesn’t include “gull”, so that it classified similar candidates instead. You never get results out of the list, and that’s why transfer learning is needed.\n",
    "\n",
    "# Visualize intermediate layer outputs\n",
    "\n",
    "Before going to transfer learning, let’s visualize intermediate layer outputs. To show list of layers, run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Will allow us to embed images in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(model.layers).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to visualize outputs of layer 311, `GlobalAveragePooling2D`, so let’s construct a model to output the intermediate layer outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "# The model which outputs intermediate layer features\n",
    "intermediate_layer_model = Model(inputs=model.input, \n",
    "                                 outputs=model.layers[311].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract features and visualize, run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img_path):\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    # Display image\n",
    "    display(img)\n",
    "    \n",
    "    # Extract features\n",
    "    features = intermediate_layer_model.predict(x)\n",
    "\n",
    "    # Visualize\n",
    "    pd.DataFrame(features.reshape(-1,1)).plot(figsize=(12, 3))\n",
    "    \n",
    "extract_features('Indian_elephant.jpeg')\n",
    "extract_features('Gull.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs of `GlobalAveragePooling2D` are 2048 dimensions features. Inception-v3 model classifies 1000 classes by using Dense layer at the end of the network, which uses these features as input. But now, we would like to classify “other” classes. So let’s remove this layer and put another one.\n",
    "\n",
    "# Add Dense layers for fine tuning\n",
    "\n",
    "Let’s add dense layers, if we want to classify **two-classes**, the code would be something like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "# Connect Dense layers at the end\n",
    "x = intermediate_layer_model.output\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# two-classes\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# Transfer Learning model\n",
    "transfer_model = Model(inputs=intermediate_layer_model.input, outputs=predictions)\n",
    "\n",
    "pd.DataFrame(transfer_model.layers).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this moment, the model trains all its variables. But we want to train only the dense layers we added, so let’s freeze untrained layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Freeze all layers\n",
    "for layer in transfer_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Unfreeze last dense layers\n",
    "transfer_model.layers[312].trainable = True\n",
    "transfer_model.layers[313].trainable = True\n",
    "\n",
    "transfer_model.compile(loss='categorical_crossentropy',\n",
    "                       optimizer='adam',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! Now we can fine-tune this model for dedicated two-classes classification.\n",
    "\n",
    "Fine tuning for two-classes classification\n",
    "Let’s classify the images below. the datasets is named Opera-Capitol datasets, which includes Opera house and Capitol 100 images for each. You can download the code to make this datasets.\n",
    "https://github.com/hayatoy/deep-learning-datasets\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*iHxe57geQ_CkXsdYnu-ZWw.png)\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "The dataset is compressed as NumPy format and stored in GitHub, you can use it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "url = 'https://github.com/hayatoy/deep-learning-datasets/releases/download/v0.1/tl_opera_capitol.npz'\n",
    "response = requests.get(url)\n",
    "dataset = np.load(BytesIO(response.content))\n",
    "\n",
    "X_dataset = dataset['features']\n",
    "y_dataset = dataset['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s split the dataset into for train and for test, here I split it 80% for train and 20% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_dataset = preprocess_input(X_dataset)\n",
    "y_dataset = np_utils.to_categorical(y_dataset)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_dataset, y_dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning the model for Opera-Capitol\n",
    "\n",
    "To train the transfer learning model, just call `fit` function. After that, let’s evaluate the model how it predict correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.fit(X_train, y_train, epochs=20,\n",
    "                   validation_data=(X_test, y_test))\n",
    "loss, acc = transfer_model.evaluate(X_test, y_test)\n",
    "print('Loss {}, Accuracy {}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(transfer_model, 'Opera_house.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
